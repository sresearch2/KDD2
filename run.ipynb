{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_captions import CreateCaption\n",
    "from pyannote.audio import Pipeline\n",
    "from utils import download_youtube_video\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "from utils import SpeakerDiarization\n",
    "import whisper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please provide Video details and tokens below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video link to summarize\n",
    "VIDEO_LINK = \"https://www.youtube.com/watch?v=O-IitVoKASo\"\n",
    "# Authentication token from hugging face to load VLM\n",
    "PYAN_AUTH_TOKEN = \"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\"\n",
    "# VLM model to be used 'Salesforce/blip2-flan-t5-xxl' or '\"liuhaotian/llava-v1.5-7b'\n",
    "VLM_MODEL = \"Salesforce/blip2-flan-t5-xxl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Speaker diarization module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "def load_models():\n",
    "    \"\"\"\n",
    "    Load Whisper and pyannote audio models for processing transcript.\n",
    "    \"\"\"\n",
    "\n",
    "    model = whisper.load_model(\"base\")\n",
    "    pipeline = Pipeline.from_pretrained(\n",
    "        \"pyannote/speaker-diarization\",\n",
    "        use_auth_token=PYAN_AUTH_TOKEN,\n",
    "    ).to(device)\n",
    "    sd = SpeakerDiarization(model, pipeline)\n",
    "    return sd\n",
    "\n",
    "\n",
    "sd = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = download_youtube_video(VIDEO_LINK, \"video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GMFLow\n",
      "Loading VLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8464645c8f4ad9984b0de50cfa84eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Models\n"
     ]
    }
   ],
   "source": [
    "# Loading VLM will take some time for the first time run to download weights\n",
    "\n",
    "cc = CreateCaption(\n",
    "    device,\n",
    "    gm_loc=\"gmflow_sintel-0c07dcb3.pth\",\n",
    "    model_type=VLM_MODEL,\n",
    "    frames_to_skip=25,  # number of frames to skip before analysing default is 5 but increase to process faster\n",
    "    batch_size=64,  # Decrease batch size if you have low gpu VRAM\n",
    ")\n",
    "get_captions = lambda video_loc: cc.captions(video_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[---------------------------------------->] \n",
      "  \n",
      "            \r Total frames read 1120/5668 \n",
      "            \r time = 186.85333333333332\n",
      "            \r good frames =45\n",
      "            \r 1/1 videos \n",
      "time 0.0s \n",
      "time_spent 199.0641849040985s\n"
     ]
    }
   ],
   "source": [
    "# get captions for important frames\n",
    "caps = get_captions(r\"videos/video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete CreateCaptions object to free VRAM if needed\n",
    "# del cc\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a49702c61184075a1eb11bf43cc7901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get access to LLama 2 - 13B\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\")\n",
    "original_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-13b-chat-hf\", load_in_4bit=True, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load PEFT adapter\n",
    "peft_model_id = \"Basha738/outputs\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "adapter_model = PeftModel.from_pretrained(original_model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "\n",
    "def gen(text):\n",
    "    toks = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    set_seed(32)\n",
    "    adapter_model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = adapter_model.generate(\n",
    "            **toks,\n",
    "            max_new_tokens=350,\n",
    "            top_k=5,\n",
    "            do_sample=True,\n",
    "        )\n",
    "    return tokenizer.decode(\n",
    "        out[0][len(toks[\"input_ids\"][0]) :], skip_special_tokens=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"### Instruction\n",
    "Given the transcript of a video with identified speakers as \"Speaker 1: ...\" and \"Speaker 2: ...\", along with captions highlighting key moments in the video, your objective is to create a concise summary of the video's content. Your analysis will consider both the transcript and the captions, without explicitly referring to them.\n",
    "\n",
    "Please pay attention to the primary speaker. If speaker names are mentioned in the captions, please infer them. However, if names are not clear, proceed to generate the summary without assuming them as \"Speaker 1\" or \"Speaker 2\".\n",
    "\n",
    "Based on the tone of the video, change the tone in the square brackets to one of the following:\n",
    "['Informative', 'Neutral', 'Relaxation', 'Encouraging', 'Enthusiastic', 'Frustration', 'Cautious', 'Sarcasm', 'Optimistic']\n",
    "\n",
    "Based on the category of the video, change the category in the square brackets to one of the following:\n",
    "['Finance', 'Investment', 'Business', 'Entrepreneurship', 'Branding', 'Macroeconomics', 'Real Estate ', 'Economical Situation', 'Entertainment Market', 'Business Ethics', 'Real Estate']\n",
    "\n",
    "# Transcript:\n",
    "{transcript}\n",
    "\n",
    "# Captions:\n",
    "{captions}\n",
    "\n",
    "### Response:\n",
    "Summary:\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = sd.get_script(\"videos/video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPEAKER_00: just a few minutes away from the closing bell now. Let's bring in Yahoo Finance's year at Blikery to break down the market action. Hello, my friend. What do we\n",
      "SPEAKER_01: here? We're seeing some outperformance by the NASDAQ yet again. And this is what's happening this year. NASDAQ up 2 % more than doubling the Dow's performance of only 0 .8 % S &P 500 up 1 and a quarter percent Russell 2000 somewhere in the middle. Now you're going to see tech that's XLK and the upper left there. That is up over 2 % followed by communication services. And communication, excuse me, discretionary. There we go. Discretionary category is up 1 .6%. Now this is interesting because guess what? The best performing sector of the year is it's XLC. That's communication services. Yet on a trailing one -year basis, you'll see that this is the worst sectors, down 25 % down considerably more last year. So let me just show you what's going on inside the sector here. Also formally the telecommunication sector. So I'm going to turn this back to a year -to -date board. And just kind of show you what's going on. And I look at this today because Spotify happens to be a member of this group. Of course that's been in the news because of the job cuts and you can see over the last year. This is a very depressed stock though it is up considerably off those lows on a percentage basis. You can see down almost 50 % year over year. Now looking at some of the other big members here. Netflix is another one that's been in the news. That's up 21 % alphabet up 13 % and so on. Just wanted to show you this because a lot of these sectors that have been the worst off last year have been the best off this year. And that's a theme that we've been going by. Now I want to show you Bitcoin as well because if you've been paying attention to the news, hope you have it has broken to the upside. And let me just put this on an interday basis for our heat map. You can see it's up 2 % over the last 24 hours over the last year. This is the biggest rally that we've had. In fact, it's the biggest rally since these all -time highs. It's nearly 50 % that we've had since we hit those all -time highs. And it doesn't look like a lot right down here, especially compared because it's at the bottom of the chart. But nevertheless, that is up nearly 50 % from the lows. Let me just show you what that looks on an interday basis. Here is a two -month look at Bitcoin. So we can see that lift off right here. We'll have to see if this continues. But 20 ,000 is my line in the sand for Bitcoin. Now we want to get to the retail sector as well. Let me see if I can find this. Here we go. E -commerce has really been picking up here. And Shopify is the stock that we want to concentrate on right now. Shopify having its best day since November. And this is after Deutsche Bank raises its recommendation on the E -commerce plate of buy from hold with a price target of $50. It looks like we've got 30 seconds to the bell here. They're saying they expect enterprise adoption to accelerate this year, which should let the company to once again outpace overall US E -commerce growth. And they're also saying Shopify is up 25 % this year. And 85 % off of its fourth quarter low. So let me just show you a max chart on Shopify before we head to the bell there. Looking like a lot of those other pandemic charts long way to go. And just broadening this out, I want to take a look at the movie sector just for a kind of a look at what's been happening on the entertainment.\n"
     ]
    }
   ],
   "source": [
    "print(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The market is seeing outperformance by the NASDAQ, with the communication services sector leading the way. The best performing sector of the year is XLC, despite being one of the worst performers last year. Bitcoin has seen a significant rally, up nearly 50% from its lows. E-commerce is picking up, with Shopify having its best day since November. The retail sector is also doing well, with Shopify up 25% this year and 85% off its fourth-quarter low.\n",
      "```\n",
      "\n",
      "\n",
      "```\n",
      "Category : 'Finance'\n",
      "Tone : 'Informative'\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gen(template.format(transcript=script, captions={x[0] for x in caps})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter your youtube link below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_LINK = \"<ENTER VIDEO LINK TO PROCESS>\"\n",
    "video_path = download_youtube_video(VIDEO_LINK, \"video_2.mp4\")\n",
    "caps = get_captions(r\"videos/video_2.mp4\")\n",
    "script = sd.get_script(\"videos/video_2.mp4\")\n",
    "print(gen(template.format(transcript=script, captions={x[0] for x in caps})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basha_video_summarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
